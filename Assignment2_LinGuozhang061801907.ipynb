{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2_LinGuozhang061801907.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NUG30/homework-2-Guozhang2020/blob/main/Assignment2_LinGuozhang061801907.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwTPfD-_mGwe"
      },
      "source": [
        "# Homework 2: Naive Bayes Email Spam Filter\n",
        "\n",
        "In this homework, we will learn how to implement the Naive Bayes classifier in order to create a simple email spam filter. This spam filter will be trained by test_emails, which will be given by a vector of tuples (emails, spam/nospam). For each tuple the first entry is a string (\"email\"), and the second entry is 0 or 1, depending whether the email contains spam words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcYY9uEZ8NNA"
      },
      "source": [
        "dictionary = ['hello', 'students', 'please', 'learn', 'for', 'the', 'exam', 'buy', 'drugs', 'today', 'sun', 'is', 'shining', 'in', 'nagoya', 'lets', 'sell', 'how', 'are', 'you', 'today?', 'do', 'your', 'homework', 'want', 'free', 'solutions?', 'hey', 'always', 'ask', 'questions', 'if','have', 'any', 'math', 'not', 'good', 'submit', 'pay'] \n",
        "\n",
        "test_emails=[\n",
        "             [\"hello students, please learn for the exam\", 0],\n",
        "             [\"hello students, please buy drugs\", 1],    \n",
        "             [\"hello, today the sun is shining in nagoya\", 0],\n",
        "             [\"lets sell drugs in nagoya\", 1],\n",
        "             [\"today learn drugs\", 1],\n",
        "             [\"how are you today?\", 0],\n",
        "             [\"hello students, please do your homework\", 0],\n",
        "             [\"hello, do you want free homework solutions?\", 1],\n",
        "             [\"hey students, please always ask questions if you have any\", 0],\n",
        "             [\"math is not good\", 1],\n",
        "             [\"math is good\", 0],\n",
        "             [\"please submit your homework\", 0],\n",
        "             [\"please buy questions\", 1],\n",
        "             [\"please pay for the exam\", 1]          \n",
        "             ]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7_jFoKsHlXZ"
      },
      "source": [
        "The feature space for our spam filter will be $\\mathcal{X}=\\{0,1\\}^d$, where $d$ denotes the number of words in the dictionary. For a feature (email) $x \\in \\mathcal{X}$ the entry $x_i$ for $i=1,\\dots,d$ is $1$ if the $i$-th word of the dictionary is contained in the email and $0$ otherwise.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihFEvEcCHI6y"
      },
      "source": [
        "# **Exercise 1**\n",
        "Implement a function which creates a feature vector out of an email and a function which creates a training set out of test emails. \n",
        "\n",
        "You would need to figure out whether a sentence contains a word, and there are functions in Python that could determine whether a string contains another string. You can consult documentation (and Google) to find out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcrE1LTy8mjy"
      },
      "source": [
        "import numpy as np\n",
        "def email_to_feature(dict, email):\n",
        "  d = len(dict)      #d denotes # of words in the dictionary\n",
        "\n",
        "#Construct an element in feature space corresponding to the email\n",
        "  vector = np.zeros(d) #Vector in feature space. Default is all zeros\n",
        "  for i in range(d):\n",
        "    if dict[i] in email: #When the word is in the email,\n",
        "      vector[i]=1     #the corresponding entry changes to 1\n",
        "  return vector\n",
        "\n",
        "def emails_to_test_samples(dict, test_emails):\n",
        "  test_samples=test_emails.copy()\n",
        "  n = len(test_samples)  #n denotes # of training samples\n",
        "\n",
        "#Construct features according to emails in test_emails and put them in test_samples\n",
        "  for i in range(n):\n",
        "    test_samples[i][0]=email_to_feature(dict,test_emails[i][0])\n",
        "  return test_samples\n",
        "#Now for test_samples[j][k][i],\n",
        "#j means j'th sample\n",
        "#if k is 0, then it is an element in feature space\n",
        "#and i means it is related to i'th word in dictionary\n",
        "#if k is 1, then it is an element in label space\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzUtdPFZ_1vR"
      },
      "source": [
        " **Recall from Lecture 6:**\n",
        "\n",
        "Given a training set  $\\mathcal{T} = \\left( (x^{(1)}, y^{(1)}) , \\dots, (x^{(n)}, y^{(n)})   \\right)$ we calculate for $i=1,\\dots,d$ the following numbers\n",
        "\\begin{align*}\n",
        "\\phi_{i\\mid y=1} &= \\frac{1+\\sum_{j=1}^n I(x^{(j)}_i = 1  \\,\\wedge \\, y^{(j)}=1 ) }{2+\\sum_{j=1}^n I(y^{(j)}=1)}\\,,\\\\\n",
        "\t\\phi_{i\\mid y=0} &= \\frac{1+\\sum_{j=1}^n I(x^{(j)}_i = 1  \\,\\wedge \\, y^{(j)}=0 )}{2+\\sum_{j=1}^n I(y^{(j)}=0)}\\,,\\\\\n",
        "\t\t\\phi_{y=1} &= \\frac{1+\\sum_{j=1}^n I(y^{(j)} = 1)}{2+n} \\,.\n",
        "\\end{align*}\n",
        "Here $I$ denoted the indicator function. We used the laplace smoothing (thats why we have the $1+$ and $2+$) in order to make sure that we will not assume probability $0$ for unknown words.\n",
        "\n",
        "Now assume we get a new feature (i.e. someone sends us an email) $x \\in \\{0,1\\}^d$. Then we can calculate for each word $i=1,\\dots,d$ the probabilities\n",
        "\\begin{align*}\n",
        "P(x_i = 1 \\mid y=1) &= \\phi_{i\\mid y=1}\\,,\\qquad &&P(x_i = 1 \\mid y=0) = \\phi_{i\\mid y=0} \\,,\\\\\n",
        "P(x_i = 0 \\mid y=1) &= 1- \\phi_{i\\mid y=1}\\,,\\qquad &&P(x_i = 0 \\mid y=0) = 1-\\phi_{i\\mid y=0} \\,. \\\\\n",
        "\\end{align*}\n",
        "\n",
        "By the Naive Bayes assumption we have for $x \\in \\{0,1\\}^d$\n",
        "\\begin{align*}\n",
        "P(x \\mid y)  = \\prod_{i=1}^d P(x_j \\mid y)\\,.\n",
        "\\end{align*}\n",
        "The probability of the new email being spam is then\n",
        "\\begin{align*}\n",
        "P(y=1 \\mid x) &= \\frac{ P(x \\mid y=1) P(y=1)}{P(x)}\\\\\n",
        "&= \\frac{\\prod_{i=1}^d P(x_i \\mid y = 1) \\cdot \\phi_{y=1}}{\\prod_{i=1}^d P(x_i \\mid y = 1) \\cdot \\phi_{y=1} + \\prod_{i=1}^d P(x_i \\mid y = 0) (1-\\phi_{y=1})}\\,.\n",
        "\\end{align*}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KdBdWJQINbe"
      },
      "source": [
        "# **Exercise 2:** \n",
        "Use the above explanation of the Naive Bayes Spam filter and implement a function which gives the probability of an email being spam given the trainings email above. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2ABCIxrT11Z"
      },
      "source": [
        "Test your spam filter with the following email.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6dIalCe-pdY"
      },
      "source": [
        "test_samples=emails_to_test_samples(dictionary, test_emails)\r\n",
        "d=len(dictionary)\r\n",
        "n=len(test_emails)\r\n",
        "#Constructing the variable for phi_i|y=1\r\n",
        "phi_i_y1=np.zeros(d)\r\n",
        "for i in range(d):\r\n",
        "  sum1=0\r\n",
        "  sum2=0\r\n",
        "  for j in range(n):\r\n",
        "    if test_samples[j][0][i]==1 and test_samples[j][1]==1:\r\n",
        "      sum1=sum1+1\r\n",
        "    if test_samples[j][1]==1:\r\n",
        "      sum2=sum2+1\r\n",
        "  phi_i_y1[i]=(1+sum1)/(2+sum2)\r\n",
        "\r\n",
        "#Constructing the variable for phi_y=1\r\n",
        "phi_y1=(1+sum2)/(2+n)\r\n",
        "\r\n",
        "#Constructing the variable for phi_i|y=0\r\n",
        "phi_i_y0=np.zeros(d)\r\n",
        "for i in range(d):\r\n",
        "  sum1=0\r\n",
        "  sum2=0\r\n",
        "  for j in range(n):\r\n",
        "    if test_samples[j][0][i]==1 and test_samples[j][1]==0:\r\n",
        "      sum1=sum1+1\r\n",
        "    if test_samples[j][1]==0:\r\n",
        "      sum2=sum2+1\r\n",
        "  phi_i_y0[i]=(1+sum1)/(2+sum2)\r\n",
        "\r\n",
        "def spam_percentage(dict,email):\r\n",
        "#Convert email to element in feature space\r\n",
        "  vector = email_to_feature(dict,email)\r\n",
        "\r\n",
        "#Calculation based on the formulas\r\n",
        "  product1=1\r\n",
        "  product2=1\r\n",
        "  for i in range(d):\r\n",
        "    term1=1\r\n",
        "    term2=1\r\n",
        "    if vector[i]==1:\r\n",
        "      term1=phi_i_y1[i]\r\n",
        "      term2=phi_i_y0[i]\r\n",
        "    if vector[i]==0:\r\n",
        "      term1=1-phi_i_y1[i]\r\n",
        "      term2=1-phi_i_y0[i]\r\n",
        "    product1=term1*product1\r\n",
        "    product2=term2*product2\r\n",
        "  P=(product1*phi_y1/(product1*phi_y1+product2*(1-phi_y1)))\r\n",
        "  return P\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo_egC7AUYoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdb78ef3-7c72-4aac-9c63-ab1cbf8832fb"
      },
      "source": [
        "email=\"the sun is shining. buy drugs now\"\n",
        "print(spam_percentage(dictionary,email))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9299429164504411\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82y_1mNLP6Lu"
      },
      "source": [
        "\n",
        "# **Exercise 3**\n",
        "Extend your spamfilter by creating a dynamical dictionary. Instead of starting with a fixed dictionary, you should now create a dictionary out of a list of emails. \n",
        "\n",
        "Write a function `create_dictionary(emails)` which returns a dictionary created from a list of emails (Give as an array of arrays `[text, spam\\nospam]`). Make sure that you do not include words more than once into the dictionary.\n",
        "To implement this function you should look up the function `split()` for a string in Python. To take care of the symbols \".\" and \",\" you can use the `replace()` function of a string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rvAqAkHz21D"
      },
      "source": [
        "import string\n",
        "def create_dictionary(emails):\n",
        "  n = len(emails)\n",
        "  emails_without_y_and_punctations=[]\n",
        "  split_emails=[]\n",
        "  for i in range(n):\n",
        "    #Use translate method to remove punctuations\n",
        "    emails_without_y_and_punctations.append(str(emails[i][0]).translate(str.maketrans('','',string.punctuation)))\n",
        "    split_emails.append(emails_without_y_and_punctations[i].split())\n",
        "  dictionary=[]\n",
        "  for i in range(n): #iterate over emails\n",
        "    for word in split_emails[i]: #iterate over words in each email\n",
        "      if word not in dictionary:\n",
        "        dictionary.append(word)\n",
        "\n",
        "  return(dictionary)\n"
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}